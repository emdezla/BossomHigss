{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python notebook used to tune the model for the Higgs Boson Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EPFL - Machine Learning - Autumn 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from proj1_helpers import *\n",
    "from implementations import *\n",
    "from helpers import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Randomisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=374534\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TRAIN_PATH = '../Data/train.csv' # TODO: download train data and supply path here \n",
    "#DATA_TEST_PATH = '../Data/test.csv' # TODO: download train data and supply path here \n",
    "\n",
    "y_train_raw, x_train_raw, ids_train_raw = load_csv_data(DATA_TRAIN_PATH,sub_sample=True)\n",
    "#_, x_test_raw, ids_test_raw = load_csv_data(DATA_TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dimensions of x_train are  (5000, 30)\n",
      "The dimension of y_train is  (5000,)\n",
      "The dimension of ids_train is  (5000,) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_train = np.copy(y_train_raw)\n",
    "x_train = np.copy(x_train_raw)\n",
    "ids_train = np.copy(ids_train_raw)\n",
    "#x_test = np.copy(x_test_raw)\n",
    "#ids_test = np.copy(ids_test_raw)\n",
    "\n",
    "print(\"The dimensions of x_train are \",x_train.shape)\n",
    "print(\"The dimension of y_train is \",y_train.shape)\n",
    "print(\"The dimension of ids_train is \",ids_train.shape, \"\\n\")\n",
    "#print(\"The dimensions of x_test are \",x_test.shape)\n",
    "#print(\"The dimension of ids_test is \",ids_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Functions needed to perform the model tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Skip to part 4) for the actual model tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_k_indices(y, k_fold, seed):\n",
    "    \"\"\"build k indices for k-fold cross-validation.\"\"\"\n",
    "    num_row = y.shape[0]\n",
    "    interval = int(num_row / k_fold)\n",
    "    np.random.seed(seed)\n",
    "    indices = np.random.permutation(num_row)\n",
    "    k_indices = [indices[k * interval: (k + 1) * interval] for k in range(k_fold)]\n",
    "    return np.array(k_indices)\n",
    "\n",
    "def cross_validation(y, x, k_indices, k, lambda_, degrees, method, initial_w, max_iters, gamma):\n",
    "    \"\"\"return the accuracy of given method.\"\"\"\n",
    "    y_test=y[k_indices[k,:]]\n",
    "    x_test=x[k_indices[k,:]]   \n",
    "    y_train=np.delete(y,k)\n",
    "    x_train=np.delete(x,k,0)\n",
    "    \n",
    "    y_pred_train, y_pred_test = prediction(x_train, y_train, x_test, degrees, method, initial_w, max_iters, gamma, lambda_)\n",
    "    \n",
    "    accuracy_train, F1_train = check_accuracy(y_pred_train, y_train)\n",
    "    accuracy_test, F1_test = check_accuracy(y_pred_test, y_test)\n",
    "    return accuracy_train, accuracy_test, F1_train, F1_test\n",
    "\n",
    "def cross_validation_visualization(lambdas, acc_tr, acc_te, f1_tr, f1_te):\n",
    "    \"\"\"visualization of the accuracy and the f1 score for the train data and the test data.\"\"\"\n",
    "    fig = plt.figure()\n",
    "    fig.set_size_inches(12,4)\n",
    "    ax_acc = fig.add_subplot(1, 2, 1)\n",
    "    ax_f1 = fig.add_subplot(1, 2, 2)\n",
    "    \n",
    "    ax_acc.set_xlabel('lambda')\n",
    "    ax_acc.set_ylabel('accuracy')\n",
    "    ax_acc.semilogx(lambdas, acc_tr, marker=\".\", color='b', label='train accuracy')\n",
    "    ax_acc.semilogx(lambdas, acc_te, marker=\".\", color='r', label='test accuracy')\n",
    "    ax_acc.set_title('Accuracy')           \n",
    "    ax_acc.grid(True)\n",
    "    ax_acc.legend(loc=2)\n",
    "    \n",
    "    ax_f1.set_xlabel('lambda')\n",
    "    ax_f1.set_ylabel('f1 score')\n",
    "    ax_f1.semilogx(lambdas, f1_tr, marker=\".\", color='b', label='train f1 score')\n",
    "    ax_f1.semilogx(lambdas, f1_te, marker=\".\", color='r', label='test f1 score')\n",
    "    ax_f1.set_title('F1 score')           \n",
    "    ax_f1.grid(True)\n",
    "    ax_f1.legend(loc=2)\n",
    "    \n",
    "    fig.savefig('cross_validation')\n",
    "\n",
    "\n",
    "def cross_validation_demo(y, x, k_fold, lambdas, degrees,seed=1, method=\"RLR\", initial_w=None,\n",
    "               max_iters=10000, gamma=1e-10):\n",
    "    \"\"\"to do\"\"\"\n",
    "    k_indices = build_k_indices(y, k_fold,seed)\n",
    "    acc_tr = []\n",
    "    acc_te = []\n",
    "    f1_tr = []\n",
    "    f1_te = []\n",
    "    for lambda_ in lambdas:\n",
    "        acc_tr_lambda=0;\n",
    "        acc_te_lambda=0;\n",
    "        f1_tr_lambda=0;\n",
    "        f1_te_lambda=0;\n",
    "        for k in range(k_fold):\n",
    "            accuracy_train, accuracy_test, f1_train, f1_test = cross_validation(y, x, k_indices, k, lambda_, degrees, method, initial_w, max_iters, gamma)\n",
    "            \n",
    "            acc_tr_lambda += accuracy_train/k_fold\n",
    "            acc_te_lambda += accuracy_test/k_fold\n",
    "            f1_tr_lambda += f1_train/k_fold\n",
    "            f1_te_lambda += f1_test/k_fold\n",
    "            \n",
    "        acc_tr.append(acc_tr_lambda)\n",
    "        acc_te.append(acc_te_lambda)\n",
    "        f1_tr.append(f1_tr_lambda)\n",
    "        f1_te.append(f1_te_lambda)\n",
    "       \n",
    "    cross_validation_visualization(lambdas, acc_tr, acc_te, f1_tr, f1_te)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-d090a0096af7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mids_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_preprocessing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mids_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"mean\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mids_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_preprocessing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mids_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"mean\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The dimensions of x_train are \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The dimension of y_train is \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x_test' is not defined"
     ]
    }
   ],
   "source": [
    "y_train, x_train, ids_train = data_preprocessing(y_train, x_train, ids_train,\"mean\")\n",
    "_, x_test, ids_test = data_preprocessing(_, x_test, ids_test,\"mean\")\n",
    "\n",
    "print(\"The dimensions of x_train are \",x_train.shape)\n",
    "print(\"The dimension of y_train is \",y_train.shape)\n",
    "print(\"The dimension of ids_train is \",ids_train.shape, \"\\n\")\n",
    "print(\"The dimensions of x_test are \",x_test.shape)\n",
    "print(\"The dimension of ids_test is \",ids_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Model tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration=0, loss=3465.042755619167\n",
      "Current iteration=1000, loss=3464.3471221903\n",
      "Current iteration=2000, loss=3463.6542679633685\n",
      "Current iteration=3000, loss=3462.9641715578114\n",
      "Current iteration=4000, loss=3462.2768110328034\n",
      "Current iteration=5000, loss=3461.592163928998\n",
      "Current iteration=6000, loss=3460.9102073104245\n",
      "Current iteration=7000, loss=3460.230917806332\n",
      "Current iteration=8000, loss=3459.5542716527984\n",
      "Current iteration=9000, loss=3458.8802447339253\n",
      "Current iteration=10000, loss=3458.2088126224553\n",
      "Current iteration=11000, loss=3457.539950619653\n",
      "Current iteration=12000, loss=3456.87363379433\n",
      "Current iteration=13000, loss=3456.209837020858\n",
      "Current iteration=14000, loss=3455.548535016095\n",
      "Current iteration=15000, loss=3454.8897023751\n",
      "Current iteration=16000, loss=3454.2333136055663\n",
      "Current iteration=17000, loss=3453.579343160892\n",
      "Current iteration=18000, loss=3452.9277654718535\n",
      "Current iteration=19000, loss=3452.2785549768028\n",
      "The train data accuracy of the model is  0.123624724944989 \n",
      "The train data f1 score of the model is  0.4247422680412371\n",
      "Current iteration=0, loss=3465.042755619167\n",
      "Current iteration=1000, loss=3464.3477399696276\n",
      "Current iteration=2000, loss=3463.655501212009\n",
      "Current iteration=3000, loss=3462.9660179829875\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-225-c2034c6862ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlambdas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdegree\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdegrees\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mcross_validation_demo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_fold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambdas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdegree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m154\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"RLR\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_w\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-40\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-42-76febfd7cd0b>\u001b[0m in \u001b[0;36mcross_validation_demo\u001b[0;34m(y, x, k_fold, lambdas, degrees, seed, method, initial_w, max_iters, gamma)\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mf1_te_lambda\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk_fold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0maccuracy_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdegrees\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0macc_tr_lambda\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0maccuracy_train\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mk_fold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-42-76febfd7cd0b>\u001b[0m in \u001b[0;36mcross_validation\u001b[0;34m(y, x, k_indices, k, lambda_, degrees, method, initial_w, max_iters, gamma)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mx_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0my_pred_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdegrees\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0maccuracy_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mF1_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projetBossomHigss/PROJET_1/Scripts/helpers.py\u001b[0m in \u001b[0;36mprediction\u001b[0;34m(x_train, y_train, x_test, degrees, method, initial_w, max_iters, gamma, lambda_)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m\"RLR\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m         \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_tr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreg_logistic_regression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphi_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0my_test_predicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphi_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0my_train_predicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphi_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreg_log\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projetBossomHigss/PROJET_1/Scripts/implementations.py\u001b[0m in \u001b[0;36mreg_logistic_regression\u001b[0;34m(y, tx, lambda_, initial_w, max_iters, gamma)\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;31m# get loss and update w.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcalculate_log_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Loss without the regularizer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m         \u001b[0mgrad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcalculate_log_loss_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mlambda_\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0mw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projetBossomHigss/PROJET_1/Scripts/implementations.py\u001b[0m in \u001b[0;36mcalculate_log_loss\u001b[0;34m(y, tx, w)\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;34m\"\"\"compute the cost by negative log likelihood.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0mN\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#degrees = [5,6,7,8,9,10]\n",
    "degrees = [5]\n",
    "k_fold = 2\n",
    "lambdas = np.logspace(-10, 0, 5)\n",
    "for degree in degrees:\n",
    "    cross_validation_demo(y_train, x_train, k_fold, lambdas, degree, seed=154, method=\"RLR\", initial_w=None, max_iters=20000, gamma=1e-40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Prediction of the test data labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree=9\n",
    "minusloglambda=2\n",
    "lambda_=10**(-loglambda)\n",
    "\n",
    "y_tr_pd, y_te_pd = prediction(X, y_train, x_test, degree, lambda_)\n",
    "name=\"submission_{0}_{1}.csv\".format(degree,minusloglambda)\n",
    "create_csv_submission(ids_test, y_te_pd, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7) Test of each Method from implementations.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using x_train and y_train as data\n",
    "\n",
    "# Parameters\n",
    "\n",
    "from helpers import *\n",
    "\n",
    "degree = 3\n",
    "tx_train = build_poly(x_train,degree)\n",
    "initial_w = np.zeros(tx_train.shape[1])\n",
    "max_iters = 1000\n",
    "gamma = 1e-30\n",
    "lambda_ = 1e-3\n",
    "\n",
    "\n",
    "#least_squares_GD(y_train, tx_train, initial_w, max_iters, gamma)\n",
    "#least_squares_SGD(y_train, tx_train, initial_w, max_iters, gamma)\n",
    "#least_squares(y_train, tx_train)\n",
    "#ridge_regression(y_train, tx_train, lambda_)\n",
    "#logistic_regression(y_train, tx_train, initial_w, max_iters, gamma)\n",
    "#reg_logistic_regression(y_train, tx_train, lambda_, initial_w, max_iters, gamma)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8) Principal Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing assembly and eigenvalue decomposition of covariance matrix step by step\n",
    "\n",
    "def standardize(tx):\n",
    "    tx_means = np.mean(tx, axis=0)\n",
    "    tx_pca = np.copy(tx)\n",
    "    \n",
    "    d = tx.shape[1]\n",
    "    n = tx.shape[0]\n",
    "    \n",
    "    for i in range(d):\n",
    "        tx_pca[:,i] = 1/np.sqrt(n-1)*(tx_pca[:,i] - tx_means[i]*np.ones([n]))\n",
    "    return tx_pca\n",
    "tx_pca = standardize(x_train)\n",
    "Cc = tx_pca.T@tx_pca\n",
    "eigc, Pc = np.linalg.eig(Cc)\n",
    "Dc = np.diag(eigc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.99745997e+06 4.69495400e+05 1.64713566e+05 3.46645379e+04\n",
      " 1.94660070e+04 2.24176514e+03 1.85633056e+03 1.26910588e+03\n",
      " 8.75888764e+02 4.94256307e+02 3.37970395e+02 3.73872355e+02\n",
      " 1.80165009e+02 1.33455902e+02 4.61683273e+01 4.00372438e+00\n",
      " 3.50132736e+00 2.75151029e+00 2.41971030e+00 1.65921609e+00\n",
      " 1.43527408e+00 1.02450098e+00 7.22270371e-01 7.09129484e-01\n",
      " 6.02506001e-01 1.85023000e-01 1.01766708e-01 5.84005525e-02\n",
      " 2.66538929e-02 7.60342251e-08]\n"
     ]
    }
   ],
   "source": [
    "# Using numpy library to compute eigenvalue decomposition of covariance matrix\n",
    "\n",
    "C = np.cov(x_train.T)\n",
    "eigs, P = np.linalg.eig(C)\n",
    "D = np.diag(eigs)\n",
    "print(eigs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([<matplotlib.axis.XTick at 0x1439d27b8>,\n",
       "  <matplotlib.axis.XTick at 0x1439d20f0>,\n",
       "  <matplotlib.axis.XTick at 0x11eaee7b8>,\n",
       "  <matplotlib.axis.XTick at 0x1439c62b0>,\n",
       "  <matplotlib.axis.XTick at 0x1439c6710>,\n",
       "  <matplotlib.axis.XTick at 0x1439c6be0>,\n",
       "  <matplotlib.axis.XTick at 0x1439c8160>,\n",
       "  <matplotlib.axis.XTick at 0x1439c85c0>,\n",
       "  <matplotlib.axis.XTick at 0x1439c8a90>,\n",
       "  <matplotlib.axis.XTick at 0x1439c8f60>,\n",
       "  <matplotlib.axis.XTick at 0x14ee53470>,\n",
       "  <matplotlib.axis.XTick at 0x14ee53940>,\n",
       "  <matplotlib.axis.XTick at 0x1439c8710>,\n",
       "  <matplotlib.axis.XTick at 0x1439c6588>,\n",
       "  <matplotlib.axis.XTick at 0x14ee532e8>,\n",
       "  <matplotlib.axis.XTick at 0x14ee5e160>,\n",
       "  <matplotlib.axis.XTick at 0x14ee5e5c0>,\n",
       "  <matplotlib.axis.XTick at 0x14ee5ea90>,\n",
       "  <matplotlib.axis.XTick at 0x14ee5ef60>,\n",
       "  <matplotlib.axis.XTick at 0x14ee25470>,\n",
       "  <matplotlib.axis.XTick at 0x14ee25940>,\n",
       "  <matplotlib.axis.XTick at 0x14ee25e10>,\n",
       "  <matplotlib.axis.XTick at 0x14ee252e8>,\n",
       "  <matplotlib.axis.XTick at 0x14ee5ea58>,\n",
       "  <matplotlib.axis.XTick at 0x14ee331d0>,\n",
       "  <matplotlib.axis.XTick at 0x14ee33630>,\n",
       "  <matplotlib.axis.XTick at 0x14ee33b00>,\n",
       "  <matplotlib.axis.XTick at 0x14ee33d30>,\n",
       "  <matplotlib.axis.XTick at 0x14ee3b4e0>],\n",
       " <a list of 29 Text xticklabel objects>)"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.bar(np.arange(1,31,1),eigs/sum(eigs)*100,align='center',width=0.4)\n",
    "plt.ylabel('Variance (%)')\n",
    "plt.title('Information Retention')\n",
    "plt.xticks(np.arange(1,30,1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.70938152385665\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "S = 0\n",
    "while S<99:\n",
    "    S += eigs[i]/sum(eigs)*100\n",
    "    i += 1\n",
    "print(S)\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = x_train@P[:,0:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 15)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'logistic_regression.py'; 'logistic_regression' is not a package",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-188-7aa92ca2c027>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlogistic_regression\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlogistic_implementation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m34\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1e-30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mNewton\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'logistic_regression.py'; 'logistic_regression' is not a package"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
